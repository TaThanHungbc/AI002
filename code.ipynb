{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e29b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "MODEL_FILE = 'handwriting_detector.keras'\n",
    "LOG_CSV = 'training_log.csv'\n",
    "BEST_MODEL_FILE = 'best_handwriting_detector.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "def build_model(input_shape=(IMG_SIZE[1], IMG_SIZE[0], 1)):\n",
    "    \"\"\"\n",
    "    Lightweight CNN with BatchNorm, Dropout and GlobalAveragePooling for lower parameters.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, (3,3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(64, (3,3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(128, (3,3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    # Extra conv for more capacity if needed\n",
    "    x = layers.Conv2D(256, (3,3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "    # Global pooling to reduce params\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    # Compile\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparams\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dfe8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(X, y):\n",
    "    # shuffle & split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "    print(\"Train/Val sizes:\", X_train.shape, X_val.shape)\n",
    "\n",
    "    model = build_model(input_shape=X.shape[1:])\n",
    "\n",
    "    # Callbacks\n",
    "    ckpt = callbacks.ModelCheckpoint(BEST_MODEL_FILE, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "    csv_logger = callbacks.CSVLogger(LOG_CSV)\n",
    "    early = callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "    # Data augmentation (light) - optional, can add if dataset small\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=3,\n",
    "        width_shift_range=0.02,\n",
    "        height_shift_range=0.02,\n",
    "        brightness_range=(0.9, 1.1),\n",
    "        shear_range=0.01,\n",
    "        zoom_range=0.02\n",
    "    )\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    steps_per_epoch = max(1, len(X_train) // BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=EPOCHS,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[ckpt, csv_logger, early])\n",
    "\n",
    "    # Save final model\n",
    "    model.save(MODEL_FILE)\n",
    "    print(f\"Saved final model to {MODEL_FILE}\")\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess_single_image\n",
    "\n",
    "def predict_image(path_or_pil, model=None, model_path=None, threshold=0.5):\n",
    "    \"\"\"Return label ('AI'/'Human') and probability of 'AI'\"\"\"\n",
    "    if model is None:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "    arr = preprocess_single_image(path_or_pil)\n",
    "    prob = float(model.predict(arr, verbose=0)[0][0])\n",
    "    label = 'AI' if prob >= threshold else 'Human'\n",
    "    return label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X = np.load('X_data.npy')\n",
    "y = np.load('y_data.npy')\n",
    "\n",
    "model, history = train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786aad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "PATH = \"sample.png\"\n",
    "\n",
    "if os.path.exists(BEST_MODEL_FILE):\n",
    "    mp = BEST_MODEL_FILE\n",
    "elif os.path.exists(MODEL_FILE):\n",
    "    mp = MODEL_FILE\n",
    "else:\n",
    "    mp = None\n",
    "print(f\"Using model file: {mp}\")\n",
    "label, prob = predict_image(PATH, model=None, model_path=mp)\n",
    "print(f\"Prediction: {label} (AI prob = {prob:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
